# Gemma

All libraries, params, training and evaluation methods can be found in the 'NLP_Project_Gemma_Mistral.ipynb' notebook.
The Gemma 2b model was the only model we were able to succesfully run, and certain experiment variations include trying out an f1 loss during training that could be better for Sequence Classification tasks.


Be sure to install the requirements by running the following code

``` pip install -r gemma_requirements.txt ```

Before running the code be sure to have the dataset in this directory with the "data.csv" filename
